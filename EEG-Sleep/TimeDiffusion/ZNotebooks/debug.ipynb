{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from diffusers.configuration_utils import ConfigMixin, register_to_config\n",
    "from diffusers.utils import BaseOutput\n",
    "from diffusers.models.embeddings import GaussianFourierProjection, TimestepEmbedding, Timesteps\n",
    "from diffusers.models.modeling_utils import ModelMixin\n",
    "from diffusers.models.unet_1d_blocks import get_down_block, get_mid_block, get_out_block, get_up_block\n",
    "from einops import rearrange, repeat, reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_out_channels = 4\n",
    "act_fn = 'silu'\n",
    "num_class_embeds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 4\n",
    "channels = 2\n",
    "batch = 3\n",
    "sample = torch.randn(batch, channels, sample_size)\n",
    "timestep = [3, 4, 5]\n",
    "labels = torch.tensor([1, 2, 3])\n",
    "class_cond = torch.tensor([1, 2, 3]).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlabels = labels.repeat(16,1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class append embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_cond = class_cond.view(batch, class_cond.shape[1], 1).expand(batch, class_cond.shape[1], sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1]],\n",
       "\n",
       "        [[2, 2, 2, 2]],\n",
       "\n",
       "        [[3, 3, 3, 3]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_cond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier +  time step class embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_proj = GaussianFourierProjection(embedding_size=block_out_channels,\n",
    "                                        set_W_to_weight=False,\n",
    "                                        log=False,\n",
    "                                        flip_sin_to_cos=False)\n",
    "timestep_input_dim = 2 * block_out_channels\n",
    "time_embed_dim = sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_embedding = TimestepEmbedding(timestep_input_dim, time_embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps = torch.tensor(timestep)\n",
    "timestep_embed = time_proj(timesteps)\n",
    "timestep_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 4])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep_embed = timestep_embed[..., None]\n",
    "timestep_embed = timestep_embed.repeat([1, 1, sample.shape[2]                                                 ])\n",
    "timestep_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 4])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep_embed = timestep_embed.broadcast_to(sample.shape[:1] + timestep_embed.shape[1:])\n",
    "timestep_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0751, -0.0751, -0.0751, -0.0751],\n",
       "         [-0.5917, -0.5917, -0.5917, -0.5917],\n",
       "         [-0.5586, -0.5586, -0.5586, -0.5586],\n",
       "         [ 0.6599,  0.6599,  0.6599,  0.6599],\n",
       "         [-0.9972, -0.9972, -0.9972, -0.9972],\n",
       "         [-0.8062, -0.8062, -0.8062, -0.8062],\n",
       "         [ 0.8294,  0.8294,  0.8294,  0.8294],\n",
       "         [ 0.7513,  0.7513,  0.7513,  0.7513]],\n",
       "\n",
       "        [[-0.9117, -0.9117, -0.9117, -0.9117],\n",
       "         [ 0.2016,  0.2016,  0.2016,  0.2016],\n",
       "         [-0.2541, -0.2541, -0.2541, -0.2541],\n",
       "         [ 0.0861,  0.0861,  0.0861,  0.0861],\n",
       "         [-0.4108, -0.4108, -0.4108, -0.4108],\n",
       "         [-0.9795, -0.9795, -0.9795, -0.9795],\n",
       "         [-0.9672, -0.9672, -0.9672, -0.9672],\n",
       "         [-0.9963, -0.9963, -0.9963, -0.9963]],\n",
       "\n",
       "        [[-0.7967, -0.7967, -0.7967, -0.7967],\n",
       "         [ 0.8620,  0.8620,  0.8620,  0.8620],\n",
       "         [ 0.8941,  0.8941,  0.8941,  0.8941],\n",
       "         [-0.7791, -0.7791, -0.7791, -0.7791],\n",
       "         [ 0.6043,  0.6043,  0.6043,  0.6043],\n",
       "         [-0.5070, -0.5070, -0.5070, -0.5070],\n",
       "         [ 0.4478,  0.4478,  0.4478,  0.4478],\n",
       "         [ 0.6269,  0.6269,  0.6269,  0.6269]]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = time_proj(labels)\n",
    "class_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_emb = class_embedding(class_labels.to(dtype=torch.float32))\n",
    "class_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 4])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_emb = class_emb.unsqueeze(1)\n",
    "class_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2214,  0.0418,  0.5393,  0.5950]],\n",
       "\n",
       "        [[ 0.4667, -0.1553,  0.1507,  0.3344]],\n",
       "\n",
       "        [[ 0.2767, -0.1439,  0.2361,  0.3369]]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep_embed = (timestep_embed + class_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1463, -0.0333,  0.4641,  0.5199],\n",
       "         [-0.3703, -0.5499, -0.0524,  0.0033],\n",
       "         [-0.3373, -0.5168, -0.0194,  0.0364],\n",
       "         [ 0.8813,  0.7017,  1.1992,  1.2549],\n",
       "         [-0.7758, -0.9554, -0.4579, -0.4022],\n",
       "         [-0.5848, -0.7644, -0.2669, -0.2112],\n",
       "         [ 1.0508,  0.8712,  1.3687,  1.4244],\n",
       "         [ 0.9727,  0.7931,  1.2906,  1.3463]],\n",
       "\n",
       "        [[-0.4450, -1.0670, -0.7610, -0.5774],\n",
       "         [ 0.6683,  0.0463,  0.3523,  0.5359],\n",
       "         [ 0.2126, -0.4094, -0.1033,  0.0803],\n",
       "         [ 0.5528, -0.0692,  0.2369,  0.4205],\n",
       "         [ 0.0559, -0.5661, -0.2601, -0.0765],\n",
       "         [-0.5128, -1.1348, -0.8287, -0.6451],\n",
       "         [-0.5005, -1.1225, -0.8164, -0.6328],\n",
       "         [-0.5296, -1.1516, -0.8455, -0.6619]],\n",
       "\n",
       "        [[-0.5201, -0.9406, -0.5606, -0.4598],\n",
       "         [ 1.1386,  0.7181,  1.0981,  1.1989],\n",
       "         [ 1.1708,  0.7502,  1.1303,  1.2311],\n",
       "         [-0.5024, -0.9230, -0.5430, -0.4421],\n",
       "         [ 0.8810,  0.4604,  0.8404,  0.9413],\n",
       "         [-0.2303, -0.6509, -0.2709, -0.1700],\n",
       "         [ 0.7244,  0.3039,  0.6839,  0.7847],\n",
       "         [ 0.9036,  0.4830,  0.8630,  0.9639]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier + timestep embedding + time step class embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_proj = GaussianFourierProjection(embedding_size=block_out_channels,\n",
    "                                        set_W_to_weight=False,\n",
    "                                        log=False,\n",
    "                                        flip_sin_to_cos=False)\n",
    "timestep_input_dim = 2 * block_out_channels\n",
    "time_embed_dim = sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_embed_dim = block_out_channels * 4\n",
    "time_mlp = TimestepEmbedding(\n",
    "    in_channels=timestep_input_dim,\n",
    "    time_embed_dim=time_embed_dim,\n",
    "    act_fn=act_fn,\n",
    ")\n",
    "time_embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_embedding = TimestepEmbedding(timestep_input_dim, time_embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps = torch.tensor(timestep)\n",
    "timestep_embed = time_proj(timesteps)\n",
    "timestep_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 16])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep_embed = time_mlp(timestep_embed)\n",
    "timestep_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0429,  0.4077, -0.2517,  0.1377, -0.2646, -0.1397,  0.1769, -0.2928,\n",
       "         -0.2095, -0.3262, -0.1920,  0.1318,  0.2291,  0.0844,  0.3249,  0.1121],\n",
       "        [-0.2860,  0.1787, -0.1658,  0.0799, -0.0692,  0.1741, -0.0674, -0.2295,\n",
       "          0.0851, -0.2297, -0.2457,  0.2494,  0.2485,  0.2833, -0.2228,  0.0233],\n",
       "        [ 0.0506,  0.1341, -0.1155,  0.0074, -0.1417, -0.0106, -0.1381, -0.1494,\n",
       "         -0.1552,  0.1464, -0.3253,  0.0620, -0.1281,  0.2302,  0.0016,  0.2741]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = time_proj(labels)\n",
    "class_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 16])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_emb = class_embedding(class_labels.to(dtype=torch.float32))\n",
    "class_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 16])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_emb = class_emb\n",
    "class_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_emb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclass_emb\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'class_emb' is not defined"
     ]
    }
   ],
   "source": [
    "class_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep_embed = (timestep_embed + class_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3112, -0.1256,  0.5594, -0.3711, -0.0022, -0.1895,  0.1036, -0.2802,\n",
       "         -0.1124, -0.0380, -0.2356,  0.0416, -0.2704,  0.2143,  0.0297, -0.0095],\n",
       "        [-0.4184,  0.0163,  0.3937, -0.2800,  0.0953, -0.4466,  0.2610, -0.1681,\n",
       "         -0.0777,  0.0624, -0.1192, -0.3193, -0.2907,  0.1534,  0.1745, -0.0607],\n",
       "        [-0.5161, -0.0913,  0.1761, -0.4073, -0.1938, -0.4360,  0.1556,  0.2373,\n",
       "          0.1228,  0.3006,  0.0466, -0.1802, -0.1473, -0.0377,  0.4903, -0.4182]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier +  Embedding class embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_proj = GaussianFourierProjection(embedding_size=12,\n",
    "                                        set_W_to_weight=False,\n",
    "                                        log=False,\n",
    "                                        flip_sin_to_cos=False)\n",
    "timestep_input_dim = 2 * block_out_channels\n",
    "time_embed_dim = block_out_channels * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 16)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep_input_dim, time_embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_embedding = nn.Embedding(num_class_embeds, time_embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 24])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps = torch.tensor(timestep)\n",
    "timestep_embed = time_proj(timesteps)\n",
    "timestep_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 4])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep_embed = timestep_embed[..., None]\n",
    "timestep_embed = timestep_embed.repeat([1, 1, sample.shape[2]])\n",
    "timestep_embed.shape                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 4])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep_embed = timestep_embed.broadcast_to(sample.shape[:1] + timestep_embed.shape[1:])\n",
    "timestep_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9573,  0.9573,  0.9573,  0.9573],\n",
       "         [-0.6163, -0.6163, -0.6163, -0.6163],\n",
       "         [ 0.4987,  0.4987,  0.4987,  0.4987],\n",
       "         [-0.9955, -0.9955, -0.9955, -0.9955],\n",
       "         [-0.2892, -0.2892, -0.2892, -0.2892],\n",
       "         [-0.7875, -0.7875, -0.7875, -0.7875],\n",
       "         [ 0.8668,  0.8668,  0.8668,  0.8668],\n",
       "         [ 0.0945,  0.0945,  0.0945,  0.0945]],\n",
       "\n",
       "        [[-0.9912, -0.9912, -0.9912, -0.9912],\n",
       "         [-0.9353, -0.9353, -0.9353, -0.9353],\n",
       "         [ 0.6412,  0.6412,  0.6412,  0.6412],\n",
       "         [ 0.7962,  0.7962,  0.7962,  0.7962],\n",
       "         [-0.1321, -0.1321, -0.1321, -0.1321],\n",
       "         [ 0.3539,  0.3539,  0.3539,  0.3539],\n",
       "         [ 0.7674,  0.7674,  0.7674,  0.7674],\n",
       "         [-0.6050, -0.6050, -0.6050, -0.6050]],\n",
       "\n",
       "        [[ 0.8482,  0.8482,  0.8482,  0.8482],\n",
       "         [ 0.0594,  0.0594,  0.0594,  0.0594],\n",
       "         [ 0.7644,  0.7644,  0.7644,  0.7644],\n",
       "         [-0.3578, -0.3578, -0.3578, -0.3578],\n",
       "         [ 0.5297,  0.5297,  0.5297,  0.5297],\n",
       "         [ 0.9982,  0.9982,  0.9982,  0.9982],\n",
       "         [ 0.6448,  0.6448,  0.6448,  0.6448],\n",
       "         [ 0.9338,  0.9338,  0.9338,  0.9338]]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_labels = time_proj(labels)\n",
    "# class_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 16])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_emb = class_embedding(labels)\n",
    "class_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8699,  0.2417, -1.5484,  0.6525,  0.1199, -0.2426, -0.5914, -0.0531,\n",
       "         -0.2414,  0.0256,  0.3370,  0.4558, -0.6298,  1.3408, -0.1176, -2.3916],\n",
       "        [-0.0326, -0.2886,  0.2077,  0.1122, -0.8515, -2.5415, -0.6106,  0.8874,\n",
       "          3.1955, -1.1452,  1.9092,  2.6204,  0.8997, -0.8625,  0.6959, -0.3227],\n",
       "        [-1.1923, -0.3724,  1.1350,  0.8426, -1.8330,  0.0184, -2.0985,  0.6326,\n",
       "          0.4346, -0.2235, -1.1300,  1.2645, -0.9645,  0.5853,  1.1197,  2.0987]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_emb = class_emb.repeat([1, sample.shape[2]])\n",
    "# .reshape(\n",
    "#                         (sample.shape[0], 1, sample.shape[2]))\n",
    "class_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8699,  0.2417, -1.5484,  0.6525,  0.1199, -0.2426, -0.5914, -0.0531,\n",
       "         -0.2414,  0.0256,  0.3370,  0.4558, -0.6298,  1.3408, -0.1176, -2.3916],\n",
       "        [-0.0326, -0.2886,  0.2077,  0.1122, -0.8515, -2.5415, -0.6106,  0.8874,\n",
       "          3.1955, -1.1452,  1.9092,  2.6204,  0.8997, -0.8625,  0.6959, -0.3227],\n",
       "        [-1.1923, -0.3724,  1.1350,  0.8426, -1.8330,  0.0184, -2.0985,  0.6326,\n",
       "          0.4346, -0.2235, -1.1300,  1.2645, -0.9645,  0.5853,  1.1197,  2.0987]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (16) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[228], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m timestep_embed \u001b[38;5;241m=\u001b[39m (\u001b[43mtimestep_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclass_emb\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (16) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "timestep_embed = (timestep_embed + class_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1463, -0.0333,  0.4641,  0.5199],\n",
       "         [-0.3703, -0.5499, -0.0524,  0.0033],\n",
       "         [-0.3373, -0.5168, -0.0194,  0.0364],\n",
       "         [ 0.8813,  0.7017,  1.1992,  1.2549],\n",
       "         [-0.7758, -0.9554, -0.4579, -0.4022],\n",
       "         [-0.5848, -0.7644, -0.2669, -0.2112],\n",
       "         [ 1.0508,  0.8712,  1.3687,  1.4244],\n",
       "         [ 0.9727,  0.7931,  1.2906,  1.3463]],\n",
       "\n",
       "        [[-0.4450, -1.0670, -0.7610, -0.5774],\n",
       "         [ 0.6683,  0.0463,  0.3523,  0.5359],\n",
       "         [ 0.2126, -0.4094, -0.1033,  0.0803],\n",
       "         [ 0.5528, -0.0692,  0.2369,  0.4205],\n",
       "         [ 0.0559, -0.5661, -0.2601, -0.0765],\n",
       "         [-0.5128, -1.1348, -0.8287, -0.6451],\n",
       "         [-0.5005, -1.1225, -0.8164, -0.6328],\n",
       "         [-0.5296, -1.1516, -0.8455, -0.6619]],\n",
       "\n",
       "        [[-0.5201, -0.9406, -0.5606, -0.4598],\n",
       "         [ 1.1386,  0.7181,  1.0981,  1.1989],\n",
       "         [ 1.1708,  0.7502,  1.1303,  1.2311],\n",
       "         [-0.5024, -0.9230, -0.5430, -0.4421],\n",
       "         [ 0.8810,  0.4604,  0.8404,  0.9413],\n",
       "         [-0.2303, -0.6509, -0.2709, -0.1700],\n",
       "         [ 0.7244,  0.3039,  0.6839,  0.7847],\n",
       "         [ 0.9036,  0.4830,  0.8630,  0.9639]]], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timestep_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_proj_t = Timesteps(block_out_channels, flip_sin_to_cos=False, downscale_freq_shift=0.0)\n",
    "timestep_input_dim = block_out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_embed_dim = block_out_channels * 4\n",
    "time_mlp = TimestepEmbedding(\n",
    "                in_channels=timestep_input_dim,\n",
    "                time_embed_dim=time_embed_dim,\n",
    "                act_fn=act_fn,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_embedding_e = nn.Embedding(num_class_embeds,\n",
    "                                    time_embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_embedding_t = TimestepEmbedding(timestep_input_dim,\n",
    "                                                     time_embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn(3, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = [3, 4, 5]\n",
    "ts = torch.tensor(timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsp = time_proj_t(ts)\n",
    "tsp.shape\n",
    "# tp = time_proj_g(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 16])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tspt = time_mlp(tsp)\n",
    "tspt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 12])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tspt = tsp.repeat([1, 1, data.shape[2]])\n",
    "tspt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 12])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tspt = tspt.broadcast_to(data.shape[:1] + tspt.shape[1:])\n",
    "tspt.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
